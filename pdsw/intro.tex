\section{Introduction}

Metadata, especially rich metadata, contains detailed information about different entities and their relationships. These entities could be users, jobs, processes, data files, or even user-defined entities. Storing and utilizing metadata already provides the basic data management functionalities in existing storage systems, including finding files, controlling file access, and tracing file creation and access time. We categorize this metadata as \textit{simple metadata} since they only contain the predefined attributes about individual entities and very basic relationships (e.g. ownership, POSIX namespace). On the contrary, \textit{rich metadata} include more than individual predefined attributes; they may store user-defined arbitrary attributes of entities and even their relationships. A typical example of rich metadata would be provenance~\cite{provenwiki} (e.g. lineage). 

Provenance is well understood in the context of art or digital libraries, where it respectively refers to the documented history of an art object, or the documentation of processes in a digital object's life cycle~\cite{moreau2011open}. In the computational systems, it indicates a recording of complete history of each data element, including the processes that generated it, the user that started the processes, and even the environment variables, parameters, and configuration files while executing. A complete provenance picture supports a huge amount of data management abilities~\cite{simmhan2005survey, silva2007provenance}. For example, the  accessing history of users reading/writing data files can help us develop an audit tool to monitor and administrate users in shared supercomputer facilities; the detailed read/write history from processes to data pieces provides a possibility to trace back suspicious executions that generated or were based on wrong datasets; reproducibility also may be possible because we have the complete history of an execution and have a better chance to re-generate the same environment to run it again. 

While there are numerous advantages to capture rich metadata like provenance, current HPC platforms still lack basic facilities to collect, store, process, and query rich metadata. The challenge comes from at least three places.

\begin{itemize}

\item \textit{Storage System Pressure}. Considering a leadership supercomputer, there might be millions of processes running on millions of cores accessing billions of files per second. In this case, recording the rich metadata, like the detailed access history of each process, will place pressure on the storage system. In addition, as storing rich metadata must not affect the application execution speed significantly, the resources (both network and disks bandwidth) dedicated to storing metadata must be limited in most cases.

\item \textit{Efficient Processing}. Even if we can collect and store these rich metadata, it is still a big challenge to process and query them. First, as rich metadata are large and can not be held in one server, a distributed processing framework is necessary in most cases. Second, some use cases require fast searching and reading, however, some require complex queries rather than simple searching, so efficient and flexible processing should be provided for them.

\item \textit{Metadata Integration}. As we have described, the rich metadata could be as diverse as the users need. They can contain predefined attributes and relationships of entities, or be extended to any user-defined attributes and relationships. Traditionally, we need different tools to process them. However, this strategy leads to waste of resources as they are not able to reuse the same metadata and processing infrastructure for different use cases. %For example, the data audit application and data verification application both need to know the file access history. We either need to store this metadata in both two applications, or only store it in one application and issue lots of cross-reference reads from other application later. 

\end{itemize}
%by providing an unified graph abstraction for all the entities and relationships
In this paper, we proposed unifying all metadata into one property graph that integrates rich metadata from different sources together: applications can store their rich metadata using graph storage APIs, and access different categories of metadata using graph query APIs~\cite{jouili2013empirical}. The benefits are twofold: first, it directly solves the integration issue by using a single representation. All applications will have the same interface to store or process metadata in a single service, where we can apply complex optimizations to improve the performance further. Second, by abstracting metadata into a graph, we are able to utilize rapidly evolving graph techniques to provide better access speed, flexible query languages, and also a high-performance graph-based distributed framework. 

This paper is organized as follows. We first introduce the definition of proposed graph model for rich metadata in Section II. In Section III, we explore the basic attributes of such graph by building an example graph using the metadata collected from the Darshan trace of a leadership supercomputer (Intrepid). In Section IV, we show the strategy to implement several critical data management functionalities based on the graph model. In Section V, we briefly introduce the relevant techniques from the graph storage and processing community, and discuss the challenges on current graph infrastructure. The last section (Section VI) concludes this paper and proposes the future work. %possible improvements