\section{Introduction}

Metadata, especially rich metadata, contains detailed information about different entities and their relationships. These entities could be users, jobs, processes, data files, or even user-defined entities. Storing and utilizing metadata already provides the basic data management functionalities in existing storage systems, including finding files, controlling file access, and tracing file creation and access time. We categorize this metadata as \textit{simple metadata} since they only contain the predefined attributes about individual entities and very basic relationships (e.g. ownership, POSIX namespace). On the contrary, \textit{rich metadata} includes more than individual predefined attributes; it may store user-defined arbitrary attributes of entities and even their relationships. A typical example of rich metadata would be provenance (e.g. lineage). 

Provenance is well understood in the context of art or digital libraries, where it respectively refers to the documented history of an art object, or the documentation of processes in a digital object's life cycle (\textit{@todo, find the ref}). In the computational systems, it indicates a recording of complete history of each data element, including the processes that generated it, the user that started the processes, and even the environment variables, parameters, and configuration files while executing. A complete provenance picture supports a huge amount of data management abilities. For example, the  accessing history of users reading/writing data files can help us develop an audit tool to monitor and administrate users in shared supercomputer facilities; the detailed read/write history from processes to data pieces provides a possibility to trace back suspicious executions that generated or were based on wrong datasets; reproducibility also may be possible because we have the complete history of an execution and have a better chance to re-generate the same environment to run it again. 

While there are numerous advantages to capture rich metadata like provenance, current HPC platforms still lack basic facilities to collect, store and process rich metadata. The challenge comes from at least three places.

\begin{itemize}

\item \textit{Storage System Pressure}. Considering a leadership supercomputer, there might be millions of processes running on millions of cores accessing billions of files per second. In this case, recording the rich metadata, like the detailed access history of each process, will place a huge pressure on the storage system. In addition, as storing rich metadata must not affect the application execution speed significantly, the resources (both network and disks bandwidth) dedicated to storing metadata must be limited in most cases.

\item \textit{Efficient Processing}. Even if we can collect and store these rich metadata, it is still a big challenge to process them. First, as rich metadata are large and can not be held in one server, a distributed processing framework is necessary in most cases. Second, many use cases require complex analysis rather than simple searching or loading, so flexible processing should be provided for them.

\item \textit{Metadata Integration}. As we have described, the rich metadata could be as diverse as the users need. They can contain predefined attributes and relationships of entities, or be extended to any user-defined attributes and relationships. Traditionally, we use different tools (system components or users applications) to store and process different subsets of metadata based on the specific usages. However, this introduces lots of unnecessary redundant metadata storage in different tools or leads to massive inefficient cross-reference operations between applications. For example, the data audit application and data verification application both need to know the file access history. We either need to store this metadata in both two applications, or only store it in one application and issue lots of cross-reference reads from other application later. 

\end{itemize}

In this paper, we proposed unifying all metadata into one property graph that integrates rich metadata from different sources together by providing an unified graph abstraction for all the entities and relationships. Applications can store their rich metadata using graph storage APIs, and access different categories of metadata using graph query APIs. The benefits are twofold: first, we directly solve the integration issue by using a single representation. All applications will have the same interface to store or process metadata in a single service, where we can apply complex optimizations to improve the performance further. Second, by abstracting metadata into a graph, we are able to utilize rapidly evolving graph techniques to provide better access speed, flexible query languages, and also a high-performance graph-based distributed framework. 

This paper is organized as follows. We first introduce the definition of proposed graph model for rich metadata in Section II. In Section III, we explore the basic attributes of such graph and discuss the possible trade-off while collecting and storing the rich metadata into graph by building an example graph using the metadata collected from the Darshan trace of a leadership supercomputer (Intrepid). In Section IV, we show the basic strategy to implement several critical data management functionalities based on the proposed property graph model. We discuss the needs coming from these real-world use cases on graph storage and processing. In Section V, we briefly introduce the relevant techniques from the graph storage and processing community, and discuss the possible improvements on current graph infrastructure. The last section (Section VI) concludes this paper and proposes the future work.