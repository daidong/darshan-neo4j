\section{Prototype and Design Choices}

In this section, we introduce a prototype system showing how to build an example metadata graph from Darshan trace. This prototype gives a general idea of the complexity and challenges of proposed graph model. Based on that, we will discuss several important design choices for \textit{gRMM} including the storage choice, the different detailed levels of metadata choice, and the interface design etc. 

\subsection{Darshan Metadata Graph Prototype}
The most unique feature of rich metadata is that it contains the relationships between different entities like users, processes, and data files. Collecting such relationships usually requires modifications on the runtime systems. In this prototype, instead of changing the runtime system of HPC platform, we exploit the Darshan trace logs as the source of rich metadata.

Darshan utility is a MPI library that can be linked to users' applications and generates I/O behaviors logs during applications are executing. Each Darshan log file represents a distinct job. The log entries of a job contain the user id who started this job, the executable file that current execution was based on, the parameters of this execution, and most importantly, the file access history of each process inside this job. To reduce log size, Darshan only stores the hashed information instead of original value.

We can abstract this information in Darshan log file to different entities in \textit{gRMM}. First, each unique user id indicates a User entity; second, each Darshan log file represents a Job entity, and all the ranks (processes) inside it are corresponding to the Processes entities; and, both the executables and data files are abstracted as Data Object entities. There is not any directory structure as Darshan only use the hashed value to distinguish different files. All the parameters are considered as the properties of Job entities. Based on this abstraction, we were able to get three-year' Darshan trace (\textit{2010, 2012, 2013}) on Intrepid machine in Argonne National Lab. into an example graph. 

\begin{table}[h]
\caption{Graph Size with different abstraction levels.}
  \label{abs}
\centering
\begin{tabular}{|c|c|l|l|}
\hline
           & \begin{tabular}[c]{@{}c@{}}Basic \\ Abstraction\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Abstraction \\ with Ranks\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Abstraction \\ with Directory\end{tabular}} \\ \hline
Vertices   &                                                              &                                                                                        &                                                                                            \\ \hline
Edges      &                                                              &                                                                                        &                                                                                            \\ \hline
Properties &                                                              &                                                                                        &                                                                                            \\ \hline
\end{tabular}
\end{table}

Table~\ref{abs} shows some statistics of such example graph. The first column named basic abstraction means that for the Execution entities, we only consider the Job. All the I/O behaviors from the processes inside a job will be considered to be from the Job entity. In this case, we got a graph containing x vertice, y edges, and z properties. For some use cases, the processes information (ranks in MPI applications) is also needed, so, in the second column of Table~\ref{abs}, we show the graph size with Processes entities. There are \textit{belongs/contains} relationships between Job and Processes entities, and also all the \textit{read/write} relationships are between Processes and Data Object now. The graph size increases sharply as you may see. 

As we have described, the directory structure is missing in current Darshan trace. However, this part of metadata is critical in most of storage systems, so we create synthetic \textit{contains} and \textit{belongs} relationships between all Data Object entities according to the files and directories size in the real file systems of Intrepid at that time. The third column of Table~\ref{abs} shows the graph size with such directory structure.

\subsection{Graph Storage Choice}
The proposed metadata graph follows a property graph model, which is different from traditional graph that only contains simple weight value on each edge. The property graph needs to store both the graph structure, which indicates the connections between nodes, and the rich data associated with the graph including properties on both nodes and edges. So, traveling through the property graph is different from traditional graph: we should only travel through limited number of edges which satisfy certain conditions, for example the edges whose type is \textit{run} instead of going through all the out-edges. 

There are several choices to store such graphs. The first choice will be a relation database, which was widely used to store provenance graph. Relation database is mature, supports huge data size with proper distributed deployment, and provides a flexible query language (SQL) to execute complex queries. According to the normal forms, storing such a graph in relation databases requires a complex scheme with multiple tables and foreign keys to refer each other. This table scheme causes poor performance while traveling the graph through edges as we need to join different tables to build a complete path. To avoid such time-consuming `join' operations, 

Comparing with relation databases, graph databases are more suitable for such property graphs. Graph traversal languages like Gremlin, Cypher are also supported in these graph databases for querying. 

Another storage choice is Key-Value storage systems. Comparing with relation databases and graph databases, they do not have any scheme. Simply mapping the nodes and edges as different objects and store their properties as the value of these objects provides a plain strategy to store the metadata graph. 

@TODO: In this section, we can show the performance of different storage systems (RDBMS, GraphDB, KeyValue) in different scenarios (Insert, Locate, Traversal). 


\subsection{Metadata Detailed Level}

@TODO: Shall we discuss the detailed level of metadata? 

\subsection{Metadata Graph Interface}

@TODO: 