\section{Graph Facilities \& Design Choices}

The limitation of traditional databases especially the relational databases has lead the development of new categories of system called \textit{graph databases} to cover the requirements of complex graph-based relationships. In the last couple of years, there have been an increasing work about graph databases. Some popular graph databases include Sones, AllegroGraph, DEX, G-Store, HyperGraphDB, InfinitGraphDB, Neo4j, Titan, and OrientDB etc.

\subsection{Graph Databases}
These graph databases can be categorized based on different metrics. Based on data storage, there are in-memory databases (e.g. Sones) and disk-based databases (e.g. AllegroGraph, DEX, Neo4j, Titan). Based on the graph data structure, there are \textit{simple graphs} databases, \textit{hypergraphs} databases, and \textit{property graphs} databases. Here, the simple graph indicates graph defined as a set of nodes connected by weighted edges. AllegroGraph and G-Store only support this simple graph data structure. Hypergraphs extends the simple graphs by allowing an edge to relate an arbitrary number of nodes. Databases like HyperGraphDB and Sones support these hypergraphs. Property graph indicates graph where nodes and edges contain properties. This property graph is the very basic of our proposed metadata graph model. Many databases like Neo4j, Titan, InfinitGraph, and DEX etc. support such graphs. 

In addition to this, some graph databases support query languages like SQL in relational databases. For example, Neo4j supports Cypher graph traversal language, Titan supports Gremlin language etc. Although most graph databases provide basic APIs to travel graphs, it is still more easy and efficient to use a query language. 

Whether support distributed deployment also classify all these databases. Only part of those databases support distributed deployment due to the fact that distributing graph into different servers with ACID and enough performance is challenge. For example, Neo4j only supports high availability deployment, which means multiple copies of each data across the cluster rather than a distributing. There are still lots of research work going on this problem.

\subsection{Storing and Indexing Requirement}

Actually, the graph database choices in our case are limited by the attributes of the metadata graphs. First, the metadata graphs are too large to fit into memory, so, the disk-based databases are better. Moreover, as the metadata graph is based on property graph model, which may store a large amount of properties, the graph could even too large to fit in one server. The distributed supports will be another necessary component. About the query language, it is not the first concern yet, but still, graph databases with a query language and some query optimizer (e.g. indexing) will be much better.  

\subsection{Traversal Requirement}

From the example use cases in previous section, we can see that the key to use the metadata graph to support different use cases is effective graph traversal. In fact, the graph size, graph data structure, and storage layouts, all decided the performance of traveling a graph. The simplest case is to deal with moderate-sized simple graph. In this cases, traveling from one or several , or even all vertices and explore their k-hop neighborhood can be possible to perform in memory as the simple graph is smaller and possible be cached into memory. 

However, traveling through a property graph like our metadata graph will be much complex. The main reason is that, during traveling, we usually need to apply filter or computations on some properties like previous provenance example shows. As these properties are too big to be cached in memory, each time, we need to load them from persistent devices. This will introduce lots of random seeking  leading to a poor performance. This is actually still a big challenge for property graph databases waiting for solving.

\subsection{Graph Processing}

In addition to the graph databases, there are also graph processing frameworks which can be used to perform computation or queries on graphs in a distributed way. Typical examples of these frameworks include Gigraph, which was designed and implemented based on Pregel computing model; GraphX, which was based on Spark computing framework; GraphLab, X-Stream, and GiGraph+ etc. 

However, most these distributed graph processing frameworks work on the unstructured graphs which are usually simply stored as a plain file in CSR or CSC formats in a general storage back-end , like local disk, HDFS, S3, or RDD etc. So, there is a big gap from deploying graph algorithms on these plain graph formats to running these algorithms on a graph database. However, the ability to run complex graph algorithms is necessary for metadata management, and this ability can not be easily satisfied using the querying or searching facilities provided by graph databases. For example, in HPC system, we can run \textit{community discovery} algorithms on metadata graph to find the `closely' data files, which can be used to optimize their physical placements for better future I/O performance. These algorithms get the whole graph involved in the computation, contain multiple iterations, and last a long time. A distributed fault-tolerant graph processing model is a much better choice than writing applications to manage all these complexity.